# ğŸ¤– InsightFusion AI: GenAI-Powered Business Document Assistant

**InsightFusion AI** is a GenAI-powered Retrieval-Augmented Generation (RAG) system that enables users to ask natural language questions across combined structured (CSV) and unstructured (PDF) business documents â€” returning accurate, citation-backed answers using local LLMs and embeddings.

---

### âœ… Features
- ğŸ” Combine **PDF reports** and **CSV data** for unified Q&A
- ğŸ¤– Powered by **LangChain + Ollama (LLaMA3 + embeddings)**
- ğŸ’¬ Ask natural questions like "Why did Q4 revenue drop?"
- ğŸ“ Context-aware answers with traceable source references
- ğŸ–¥ï¸ Optional **Streamlit UI** for interactive exploration

---

### ğŸ› ï¸ Tech Stack

- Python 3.10+
- LangChain, FAISS
- Ollama (with `llama3` + `nomic-embed-text`)
- PyMuPDF, Pandas
- Streamlit (for web UI)

---

### ğŸ’¼ Real-World Use Cases

- Analyze financial reports to explain performance changes
- Summarize legal or policy documents for quick review
- Extract key trends from monthly departmental CSVs
- Enable customer service agents to query internal PDFs + reports

---

### ğŸš€ Getting Started

#### 1. Install Requirements

```bash
pip install -r requirements.txt
```

#### 2. Install and Run Ollama

```bash
# Install Ollama: https://ollama.com
ollama pull llama3
ollama pull nomic-embed-text
```

#### 3. Run the CLI Tool

```bash
python main.py
```

#### 4. Use Streamlit UI (optional)

```bash
streamlit run streamlit_app.py
```

---

### ğŸ“ Project Structure

```
insightrag/
â”œâ”€â”€ ingest/            # Loaders for PDFs and CSVs
â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â””â”€â”€ csv_loader.py
â”œâ”€â”€ rag/               # Vector store and RAG chain logic
â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â””â”€â”€ qa_chain.py
â”œâ”€â”€ data/              # Upload your sample files here
â”œâ”€â”€ main.py            # Core app logic
â”œâ”€â”€ streamlit_app.py   # Optional web interface
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### ğŸ§ª Sample Queries
- "Summarize key points from the policy document."
- "What were the most expensive departments last month?"
- "Why did revenue decrease in Q3?"

---

### ğŸ“Œ Notes
- Ollama must be running locally before you launch the app.
- You can switch to other LLMs or embedding models by modifying `qa_chain.py` and `vectorstore.py`.

---
